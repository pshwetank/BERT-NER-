{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3519d60",
   "metadata": {},
   "source": [
    "# Named Entity Recognition(NER) using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955de089",
   "metadata": {},
   "source": [
    "### **Problem statement:** Find and highlight the organisation names in the given statements. \n",
    "\n",
    "> **Input:** Conflict of interest Name is an employee and stockholder of Novo Nordisk A/S. \\\n",
    "> **Output:** Conflict of interest Name is an employee and stockholder of < e1 >Novo Nordisk A/S < /e1 >.\n",
    "\n",
    "\n",
    ">**Input:** I have conflicting interests with Microsoft, Google and Myntra. \\\n",
    ">**Output:** I have conflicting interests with < e1 >Microsoft< /e1 >, < e1 >Google< /e1 > and < e1 >Myntra< /e1 >.\n",
    "\n",
    "### **Solution summary:** \n",
    "The implemented solution uses the pretrained BERT model available on Huggingface model repository [[LINK]](https://huggingface.co/dslim/bert-base-NER). The model is finetuned enough for the task at hand. The preprocessing part which includes tokenisation of words in a sentence and their encoding are readily available as pipeline module in transformers library. The main concern is to correctly parse the model outputs that will require understanding the output structure.\n",
    "\n",
    "![Flow Diagram](figures/flow_diagram.png)\n",
    "\n",
    "### **This notebook will describe the steps involved in implementing the solution and explain the reason behind  particular design choices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97661f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca95c",
   "metadata": {},
   "source": [
    "## Choice of architecture\n",
    "\n",
    "BERT(Bidirectional Encoder Representations from Transformers) is a transformer model that can be used for variety of NLP tasks like Question Answering, Next-sentence predication, Text classification and named entity recognition. \n",
    "\n",
    "Generally, the important step in customizing BERT for different downstream tasks is to use the final hidden representation generated for each token encoding. \n",
    "\n",
    "![BERT for NER](figures/BERT_NER.png)\n",
    "\n",
    "In our case for NER task, we utilise the final hidden layer representations by feeding them into the softmax function from where we select the class with maximum probability.\n",
    "\n",
    "![Softmax](figures/softmax.png)\n",
    "    where **t** refers to the particular class out of given classes and **h** refers to the corresponding hidden representation.\n",
    "    \n",
    "### For our case of finding organisation names that generally starts with capital letter, we use the Cased BERT model. \n",
    "\n",
    "> In situations, where we are concerned with finding pronouns, we can use uncased BERT model and embedding, which usually converts the input text to lowercase.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06cf0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_classifier = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec818cf",
   "metadata": {},
   "source": [
    "## Structure of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64b3fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99945873,\n",
       "  'index': 1,\n",
       "  'word': 'Vijay',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.9989275,\n",
       "  'index': 6,\n",
       "  'word': 'Google',\n",
       "  'start': 22,\n",
       "  'end': 28}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_classifier(\"Vijay used to work at Google.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a6408",
   "metadata": {},
   "source": [
    "#### Here, we are interested in the following attributes of each predicted entity:\n",
    "\n",
    "- **'entity'** : The predicted class of word token. \n",
    "\n",
    "- **'word'** : Tokenised word representation\n",
    "\n",
    "- **'start'** : Starting position of word in sentence\n",
    "\n",
    "- **'end'** : Ending position of word in sentence\n",
    "\n",
    "#### Particularly, we will filter the following entities for our purpose:\n",
    "\n",
    "- **B-ORG** : Beginning of an organization right after another organization\n",
    "\n",
    "- **I-ORG** : Inside the organization present previously\n",
    "\n",
    "#### Also, the structure of tokenised word representation also needs to be taken into consideration:\n",
    "\n",
    "- Presence of ## in a word, for example '##tra' ,indicates that it is not a seperate entity but a subpart of some another entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306d427",
   "metadata": {},
   "source": [
    "## Post-processing (Parsing)\n",
    "\n",
    "<img src=\"figures/parsing.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dc863d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_parser(entity_lst):\n",
    "    '''\n",
    "    Parsing function to parse and select the organisation names from the entity_lst output from BERT model.\n",
    "    '''\n",
    "    \n",
    "    n_entities = len(entity_lst)\n",
    "    org_dict = OrderedDict()\n",
    "    \n",
    "    for word_dict in entity_lst:\n",
    "        \n",
    "        word_ent = word_dict['word']\n",
    "        cur_word = word_dict['word'].replace(\"#\", \"\")\n",
    "        start_pos = word_dict['start']\n",
    "        end_pos = word_dict['end']\n",
    "        entity_type = word_dict['entity']\n",
    "        \n",
    "        if not word_ent.count(\"#\") and entity_type == 'B-ORG':    \n",
    "            org_dict[cur_word] = {'start':start_pos, 'end':end_pos}\n",
    "            #print(\"Item added:\", cur_word)\n",
    "        \n",
    "        elif entity_type == 'I-ORG':\n",
    "            \n",
    "            prev_entity = list(org_dict.items())[-1]\n",
    "            prev_word = prev_entity[0]\n",
    "            new_word = prev_word + cur_word\n",
    "            new_endpos = end_pos\n",
    "            \n",
    "            del org_dict[prev_word]\n",
    "            \n",
    "            prev_start = prev_entity[1]['start']\n",
    "            org_dict[new_word] = {'start':prev_start, 'end':new_endpos}\n",
    "\n",
    "            \n",
    "    return org_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2808eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tags(input_txt, org_dict):\n",
    "    tagged_txt = deepcopy(input_txt)\n",
    "    for i, entries in enumerate(org_dict.items()):\n",
    "        sent = list(tagged_txt)\n",
    "        cur_start_pos = entries[1]['start'] + i*(8) + i\n",
    "        cur_end_pos = entries[1]['end'] + (i+1) + i*8\n",
    "        sent.insert(cur_start_pos, \"<e1>\")\n",
    "        sent.insert(cur_end_pos, \"</e1>\")\n",
    "        tagged_txt = ''.join(sent)\n",
    "        #print(tagged_txt)\n",
    "    return tagged_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2925e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organisation_Search_Utility(query_txt, ner_model):\n",
    "    '''\n",
    "    Final wrapper function with all the steps performed at once to obtain the required output\n",
    "    '''\n",
    "    bert_output = ner_model(query_txt)\n",
    "    org_dct = bert_parser(bert_output)\n",
    "    print(\"Ordered dictionary of organisations:\", org_dct)\n",
    "    tagged_txt = add_tags(query_txt, org_dct)\n",
    "    print(\"\\nTagged output:\")\n",
    "    print(tagged_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c07799",
   "metadata": {},
   "source": [
    "## Final testing of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8ec7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test case 1\n",
    "query = \"I have conflicting interests with Microsoft, Google and Myntra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f288c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered dictionary of organisations: OrderedDict([('Microsoft', {'start': 34, 'end': 43}), ('Google', {'start': 45, 'end': 51}), ('Myntra', {'start': 56, 'end': 62})])\n",
      "\n",
      "Tagged output:\n",
      "I have conflicting interests with <e1>Microsoft</e1>, <e1>Google</e1> and <e1>Myntra</e1>\n"
     ]
    }
   ],
   "source": [
    "Organisation_Search_Utility(query, ner_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e791104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test case 2\n",
    "query = \"Conflict of interest Name is an employee and stockholder of Novo Nordisk A/S.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d1ee62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered dictionary of organisations: OrderedDict([('NovoNordiskA/S', {'start': 60, 'end': 76})])\n",
      "\n",
      "Tagged output:\n",
      "Conflict of interest Name is an employee and stockholder of <e1>Novo Nordisk A/S</e1>.\n"
     ]
    }
   ],
   "source": [
    "Organisation_Search_Utility(query, ner_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269c847",
   "metadata": {},
   "source": [
    "### More test cases for robustness (and out of curiosity :-) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23f3dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra test case\n",
    "query = \"I have conflicting interests with Zerodha, LayerIV and Cred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c662aed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered dictionary of organisations: OrderedDict([('Zerodha', {'start': 34, 'end': 41}), ('LayIV', {'start': 43, 'end': 50}), ('Cred', {'start': 55, 'end': 59})])\n",
      "\n",
      "Tagged output:\n",
      "I have conflicting interests with <e1>Zerodha</e1>, <e1>LayerIV</e1> and <e1>Cred</e1>\n"
     ]
    }
   ],
   "source": [
    "Organisation_Search_Utility(query, ner_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a021f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra test case\n",
    "query = \"Stock prices of SAIL are roaring high this week.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ba4adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered dictionary of organisations: OrderedDict([('SAIL', {'start': 16, 'end': 20})])\n",
      "\n",
      "Tagged output:\n",
      "Stock prices of <e1>SAIL</e1> are roaring high this week.\n"
     ]
    }
   ],
   "source": [
    "Organisation_Search_Utility(query, ner_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5921c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra test case\n",
    "query = \"Google Cloud Platform is quite important for machine learning deployments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66964f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered dictionary of organisations: OrderedDict([('GoogleCloudPlatform', {'start': 0, 'end': 21})])\n",
      "\n",
      "Tagged output:\n",
      "<e1>Google Cloud Platform</e1> is quite important for machine learning deployments.\n"
     ]
    }
   ],
   "source": [
    "Organisation_Search_Utility(query, ner_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('experiments': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd05a852903ad70e86c3b9de77e947d89d0a30806c7540c78909242232f2e97c78c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
